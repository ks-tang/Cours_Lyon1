{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Initiation au CNN avec Pytorch"],"metadata":{"id":"xruG3XwOTC9g"}},{"cell_type":"markdown","source":["Ce TP s'effectue individuellement ou en binome. Veuillez respecter les consignes suivantes pour le rendu de votre travail :\n","\n","* Renommez le selon le format suivant : \"DL_2023_TP_Torch_prenom1_nom1_prenom2_nom2.ipynb\".\n","* Veillez à ce que votre nom et prénom soient complétés dans la cellule ci-dessous.\n","* Veillez à avoir bien exécuté toutes les cellules de code et que les résultats soient tous bien visible dans le notebook sans nécessiter une ré-exécution.\n","* Partagez le notebook avec hana.sebia@univ-lyon1.fr"],"metadata":{"id":"Y1xjsLpwTI4L"}},{"cell_type":"markdown","source":["Veuillez compléter vos noms et prénoms ci-dessous :\n","\n","*   **Prenom 1** : Kévin\n","*   **Nom 1** : TANG\n","*   **Prenom 2** : Yann\n","*   **Nom 2** : VINCENT"],"metadata":{"id":"ofu05FedTLNW"}},{"cell_type":"markdown","source":["Ce TP est une introduction au framework Pytorch. Nous allons construire une des premières architectures de CNN présenté par [Yann Le Cun](https://fr.wikipedia.org/wiki/Yann_Le_Cun), un [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf).\n","\n","L'architecture du LeNet est détaillée dans la figure ci-dessous:"],"metadata":{"id":"ijiyhtUZTNNS"}},{"cell_type":"markdown","source":["![leNet5.jpeg](leNet5.jpeg \"Architecture Lenet\")"],"metadata":{"id":"932waKRATQxu"}},{"cell_type":"code","source":["# on importe les bibliothèques pytorch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","torch.manual_seed(42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PX4n7OrqTT1d","executionInfo":{"status":"ok","timestamp":1702907156010,"user_tz":-60,"elapsed":6329,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}},"outputId":"7af221a6-3d88-41da-8bfc-ca32924c9751"},"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7d9c38149590>"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print (\"CUDA device not found.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXZIL15pTV7S","executionInfo":{"status":"ok","timestamp":1702907156011,"user_tz":-60,"elapsed":7,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}},"outputId":"dfdbf6a4-eb3e-40fa-ecb5-e44fe6152a23"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA device not found.\n"]}]},{"cell_type":"markdown","source":["## Chargement du jeu de données\n","La tâche que nous souhaitons réaliser est la classification d'image [MNIST](https://fr.wikipedia.org/wiki/Base_de_donn%C3%A9es_MNIST). La base de données MNIST (Modified National Institute of Standards and Technology) est une base de données de chiffres écrits à la main. C'est un jeu de données très utlisé en apprentissage automatique. Il regroupe 60000 images d'apprentissage et 10000 images de test. On peut télécharger ces données à partir du module dataset de torchvision en séparant le chargement du train/test set. Il est également possible d'appliquer un ensemble de transformations aux images dès le chargement."],"metadata":{"id":"rROAi0IfTZFO"}},{"cell_type":"code","source":["from torchvision import datasets, transforms # On peut importer directement le dataset de pytorch\n","\n","# On définit transforms qui permet de redimensionner l'image en 32*32 et de la transformer en tensor\n","transforms = transforms.Compose([transforms.Resize((32, 32)),\n","                                 transforms.ToTensor(),\n","                                 transforms.Normalize((0.5,), (0.5,))])\n","\n","# On télécharge et on créer la dataset d'entraienement à l'aide du module datasets de torchvision\n","train_dataset = datasets.MNIST(root='mnist_data',\n","                               train=True,\n","                               transform=transforms,\n","                               download=True)\n","\n","# On télécharge et on créer la dataset de test à l'aide du module datasets de torchvision\n","valid_dataset = datasets.MNIST(root='mnist_data',\n","                               train=False,\n","                               transform=transforms)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_L5hFMMTcp0","executionInfo":{"status":"ok","timestamp":1702907165866,"user_tz":-60,"elapsed":9859,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}},"outputId":"0343e437-145e-42de-ac4f-0b0f83338a22"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 65426989.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 26489327.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 121827286.44it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist_data/MNIST/raw\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 11082332.03it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist_data/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["Une fois les train/test sets chargés, on définit des dataloaders qui permettent de créer des batchs pour la phase train de l'apprentissage de notre modèle comme suit :"],"metadata":{"id":"384scjYWTj9E"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","BATCH_SIZE = 32 #taille du batch size\n","\n","# On définit le data loaders d'entraienement . Le data loaders permet de créer des batchs. On doit lui renseigner le batch size.\n","train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=BATCH_SIZE,\n","                          shuffle=True)\n","# On définit le data loaders de validation .\n","valid_loader = DataLoader(dataset=valid_dataset,\n","                          batch_size=BATCH_SIZE,\n","                          shuffle=False)"],"metadata":{"id":"adCwqM6kTlsX","executionInfo":{"status":"ok","timestamp":1702907165866,"user_tz":-60,"elapsed":9,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Définition du modèle"],"metadata":{"id":"SMraHl8_Tniq"}},{"cell_type":"markdown","source":["---\n","<span style='color:Green'>**Question**</span>\n","\n","Implémenter la classe LeNet avec l'architecture proposée en utilisant l’interface [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) de PyTorch:\n","\n","---\n","\n","\n","Dans l'initialisation de la classe LeNet\n","1. La première couche [convolutive](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) avec 6 noyaux de taille 5×5 et le stride de 1.\n","2. Une couche de [sous-échantillonnage/mise](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) en commun avec 6 noyaux de taille 2×2.\n","3. La deuxième couche convolutive avec la même configuration que la première, cette fois avec 16 filtres. La sortie de cette couche est de 10×10×16.\n","4. La deuxième couche de mise en commun. La logique est identique à celle de la précédente, mais cette fois, la couche comporte 16 filtres. La sortie de cette couche est de taille 5×5×16.\n","5. La dernière couche convolutive avec 120 noyaux 5×5.\n","6. La dernière couche est un réseau de [neurones simple](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) comme détaillé dans l'architecture ci-dessus.\n","\n","Toute couche convolutive doit être suivi d'une [ normalisation](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d) et d'une fonction d'activation [ReLu](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu)\n","\n","Dans la fonction forward de la classe LeNet définissez le passage de la donnée x en appliquant à la fin un [softmax](https://pytorch.org/docs/stable/generated/torch.nn.functional.softmax.html) pour calculer la probabilité d'appartenance à la classe des chiffres de mnist.\n","\n","\n","**Indice**\n","Indice: l’utilisation de la méthode [.view()](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) ou de la couche [nn.Flatten()](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html) peut être utile pour ré-arranger les tenseurs avant ou après les couches linéaires. Par exemple, x.view(-1, 1, 28, 28) permet de transformer un tenseur de dimensions 784 en un tenseur de dimensions (batch, 1, 28, 28)…"],"metadata":{"id":"5dx5dq3tTqEh"}},{"cell_type":"code","source":["\n","class LeNet(nn.Module): # On créer la classe LeNet qui hérite de la classe mère Module\n","\n","    def __init__(self): # On définit\n","        super(LeNet, self).__init__()\n","\n","        self.feature_extractor = nn.Sequential(\n","            # Couche 1\n","            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n","            nn.BatchNorm2d(6),\n","            nn.ReLU(),\n","\n","            # Couche 2\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            # Couche 3\n","            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU(),\n","\n","            # Couche 4\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            # Couche 5\n","            nn.Conv2d(16, 120, kernel_size=5, stride=1, padding=0),\n","            nn.BatchNorm2d(120),\n","            nn.ReLU(),\n","        )\n","\n","         ## La dernière couche est un réseau de neurones simple\n","        self.classifier = nn.Sequential(\n","           #\n","           #\n","           #\n","            nn.Linear(120 * 1 * 1, 84),  # Ajustez la taille d'entrée en fonction de la sortie de la dernière couche convolutive\n","            nn.ReLU(),\n","            nn.Linear(84, 10),  # 10 pour la classification des chiffres de 0 à 9 dans MNIST\n","        )\n","\n","    def forward(self, x): # on défini le passage de nos données\n","\n","        x = self.feature_extractor(x)            # On applique l'extracteur\n","        x = x.view(-1, 120 * 1 * 1)            # On réarrange la structure de x\n","        logits = self.classifier(x)       # Prédire la classe des images dans x\n","        probs = nn.functional.softmax(logits, dim=1)        # calculer les probabilités d'appartenance à partir des prédictions\n","        return logits, probs\n","\n","\n","net = LeNet()\n","print(net) # On peut afficher les paramètres du modèle"],"metadata":{"id":"uNO304vlTsL1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702907165866,"user_tz":-60,"elapsed":6,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}},"outputId":"7c2ab4f8-de6c-4616-cd37-b24cc3677095"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["LeNet(\n","  (feature_extractor): Sequential(\n","    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n","    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n","    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU()\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n","    (9): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU()\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=120, out_features=84, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=84, out_features=10, bias=True)\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["---\n","<span style='color:Green'>**Question**</span>\n","\n","Compléter et commenter la fonction train(chaque ligne du code), celle-ci permet d'entrainer votre modèle:\n","\n","---"],"metadata":{"id":"HgUom2EwTt_g"}},{"cell_type":"code","source":["# On créer la fonction qui permet d'entrainer le modèle\n","\n","def train(train_loader, model, criterion, optimizer):\n","    '''\n","    Function for the training step of the training loop\n","    '''\n","    model.train() # entrainement du model\n","    running_loss = 0 # initialisation de la loss\n","\n","    for X, y_true in train_loader:\n","\n","        optimizer.zero_grad() # réinitilisation des gradients\n","\n","        X = X.to(device) # on envoie les données X sur la GPU\n","        y_true = y_true.to(device) # on envoie les données Y sur la GPU\n","\n","        # Forward pass (on passe les données dans le modèle)\n","        y_hat, _ = model(X)\n","        loss = criterion(y_hat, y_true) # Calcule la perte entre les prédictions et les vraies étiquettes\n","\n","        # Rétropropagation du gradient\n","        loss.backward()\n","        optimizer.step()  # Applique une étape d'optimisation pour mettre à jour les poids du modèle\n","\n","        running_loss += loss.item()\n","\n","    running_loss /= len(train_loader) # Calcule la loss moyenne pour cet epoch\n","    return model, optimizer, running_loss # Retourne le modèle mis à jour, l'optimiseur et la perte moyenne"],"metadata":{"id":"9VmgCyMOTvyi","executionInfo":{"status":"ok","timestamp":1702907165866,"user_tz":-60,"elapsed":4,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["---\n","<span style='color:Green'>**Question**</span>\n","\n","En vous inspirant de la fonction train, completer la fonction validate, celle-ci permet de tester votre modèle:\n","\n","---"],"metadata":{"id":"-HkkBRoBTxmk"}},{"cell_type":"code","source":["# On créer la fonction qui permet de valider le modèle\n","\n","def validate(valid_loader, model, criterion):\n","    '''\n","    Function for the validation step of the training loop\n","    '''\n","\n","    model.eval()\n","    running_loss = 0\n","\n","    for X, y_true in valid_loader:\n","\n","        X = X.to(device)\n","        y_true = y_true.to(device)\n","\n","        # Forward pass and record loss\n","        y_hat, _ = model(X)\n","        loss = criterion(y_hat, y_true)\n","        running_loss += loss.item()\n","\n","    running_loss /= len(valid_loader)\n","    return model, running_loss"],"metadata":{"id":"24Xcw0gVTyvl","executionInfo":{"status":"ok","timestamp":1702907166267,"user_tz":-60,"elapsed":405,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["---\n","<span style='color:Green'>**Question**</span>\n","\n","Ecrivez la fonction training_loop qui prend en paramètre le model, le criterion, l'optimizer, le train_loder, le valid_loader et le nombre d'épochs. Cette fonction permet de faire une étape de train et une étape de validate par epoch. Affichez l'erreur d'apprentissage et de validation toutes les 5 épochs.\n","\n","---\n","---\n","**Note**\n","Lors de la validation, les gradients ne doivent pas être modifiés ([.no_grad](https://pytorch.org/docs/stable/generated/torch.no_grad.html)).\n","\n","---"],"metadata":{"id":"gGVmMNEgT1A-"}},{"cell_type":"code","source":["def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, print_every=5):\n","    model.to(device)\n","\n","    for epoch in range(epochs):\n","        # Entraînement\n","        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer)\n","\n","        # Validation\n","        model, valid_loss = validate(valid_loader, model, criterion)\n","\n","        # Affichage des résultats toutes les 'print_every' époques\n","        if (epoch + 1) % print_every == 0 or epoch == 0:\n","            print(f'Epoch {epoch + 1}/{epochs} => '\n","                  f'Training Loss: {train_loss:.4f}, '\n","                  f'Validation Loss: {valid_loss:.4f}')\n","\n","    return model, optimizer"],"metadata":{"id":"0P1pDd_oT37K","executionInfo":{"status":"ok","timestamp":1702907166268,"user_tz":-60,"elapsed":5,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["---\n","<span style='color:Green'>**Question**</span>\n","\n","Définissez un [optimizer]( https://pytorch.org/docs/stable/optim.html#module-torch.optim) ainsi qu'une fonction de perte adaptés et justifiez votre choix.\n","\n","---"],"metadata":{"id":"PXL8fVZBT5tk"}},{"cell_type":"code","source":["import torch.optim as optim\n","\n","model = net.to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss() # Pour les problemes de classification : CrossEntropy\n","\n","\n","# L'optimiseur Adam a été choisi en raison de sa capacité à gérer efficacement\n","# les jeux de données volumineux et les modèles complexes, grâce à ses taux d'apprentissage adaptatifs.\n","\n","# La fonction de perte CrossEntropyLoss est appropriée pour les problèmes de classification,\n","# car elle mesure l'écart entre la distribution de probabilité prédite par le modèle et la distribution réelle des étiquettes,\n","# favorisant ainsi une convergence efficace."],"metadata":{"id":"sePGNFEfT7bf","executionInfo":{"status":"ok","timestamp":1702908750495,"user_tz":-60,"elapsed":285,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["---\n","<span style='color:Green'>**Question**</span>\n","\n","Lancez l'entrainement de votre modèle en choisissant un nombre d'epoch judicieusement.\n","\n","---"],"metadata":{"id":"KlRh2_eKT87m"}},{"cell_type":"code","source":["N_EPOCHS = 25\n","model, optimizer = training_loop(model, criterion, optimizer, train_loader, valid_loader, N_EPOCHS, print_every=5)"],"metadata":{"id":"EwJJWM20T-OF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702908599160,"user_tz":-60,"elapsed":1228021,"user":{"displayName":"yann vincent","userId":"02789094578402830526"}},"outputId":"0542e29a-89c7-4e4b-c365-1a402433d2a3"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/25 => Training Loss: 0.0301, Validation Loss: 0.0334\n","Epoch 5/25 => Training Loss: 0.0192, Validation Loss: 0.0305\n","Epoch 10/25 => Training Loss: 0.0135, Validation Loss: 0.0280\n","Epoch 15/25 => Training Loss: 0.0092, Validation Loss: 0.0333\n","Epoch 20/25 => Training Loss: 0.0078, Validation Loss: 0.0285\n","Epoch 25/25 => Training Loss: 0.0066, Validation Loss: 0.0397\n"]}]}]}